{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"03_train_SepFormer_train.ipynb","provenance":[],"collapsed_sections":["5qr2WJRMVgte","UOQp8xdJ_shO","WQbKVc7lVPB4","aijWCd5OVTx9"],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"oQ2moaOG1J6y","executionInfo":{"status":"ok","timestamp":1624051500724,"user_tz":300,"elapsed":2684,"user":{"displayName":"JOSE ALBERTO ARANGO SÁNCHEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLxNP2GGLDngTSyVoX3tPmWhP9lveqt_TTiVGNB1jwCqiDVEMsi_RA24JdUWWb3Y1wlKlv16oda_8IGBBsSsKV_GrzfRIEv6TW3p_edCCedZVLOa8ev3I6uA5qc3a6pMNzua1Hl7mNmly5JUSWTZTSI07C3XZ1htt6oSYEcDj24zcHjj2JsmyCVMtd04XJq5Fjs2sB7BZTesrRrbzXfoZlohZtRqzFlZWu-Q5xKfoMhpUiogwnNerzSEK9Rk6MlwZN0T18dZizvT-eEqW12g1iuKj7e5zKLQVoMtnU6AzffMH-MjIxUfxYFU57d5zJBGF26z674EZkRmuHXXUZTPU6lKU-qNX59fd6OFjLnMTSGuap7iYW_o1ZUQEXiFKUWXQGWdNc1_0hj7xPF7fjYDBJZxnSPxeeIR9U0X7fXONBgqKAy32hQ8V-nGCY62PZRtjDFwi4nFVIok6_jGtiqFQK3FnNZ7zhJnDxhjDITy7LeXt0hBELVT-qB_9e38FZHnhSekkW15x_AFITdh_GUxCjoftPD8Gwi1RWAARCI6t-tKySdjqHkRIPwqhk6lcEy0wAUB8oDiBFpT1G8eAhsW-jFHHY7UBYOJXUqmgi91e2g1dmvxdQHr4M-WesD0NPTCj3IjplrykccTg8fiexbm5k9Sz3_rLPbVgZGDwcLqOp7jtDNyd0gtpZYWde04NcbTTC9WxenUpej7anaX68wzznN1RIvbAaLF4roPs0e0M7QKN03u8zEX0CFnDzniTFiNQI6vya=s64","userId":"16388542354054473882"}}},"source":["%%capture\n","!pip install speechbrain"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ia1JNiPknZB","executionInfo":{"status":"ok","timestamp":1624050375821,"user_tz":300,"elapsed":4248,"user":{"displayName":"JOSE ALBERTO ARANGO SÁNCHEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLxNP2GGLDngTSyVoX3tPmWhP9lveqt_TTiVGNB1jwCqiDVEMsi_RA24JdUWWb3Y1wlKlv16oda_8IGBBsSsKV_GrzfRIEv6TW3p_edCCedZVLOa8ev3I6uA5qc3a6pMNzua1Hl7mNmly5JUSWTZTSI07C3XZ1htt6oSYEcDj24zcHjj2JsmyCVMtd04XJq5Fjs2sB7BZTesrRrbzXfoZlohZtRqzFlZWu-Q5xKfoMhpUiogwnNerzSEK9Rk6MlwZN0T18dZizvT-eEqW12g1iuKj7e5zKLQVoMtnU6AzffMH-MjIxUfxYFU57d5zJBGF26z674EZkRmuHXXUZTPU6lKU-qNX59fd6OFjLnMTSGuap7iYW_o1ZUQEXiFKUWXQGWdNc1_0hj7xPF7fjYDBJZxnSPxeeIR9U0X7fXONBgqKAy32hQ8V-nGCY62PZRtjDFwi4nFVIok6_jGtiqFQK3FnNZ7zhJnDxhjDITy7LeXt0hBELVT-qB_9e38FZHnhSekkW15x_AFITdh_GUxCjoftPD8Gwi1RWAARCI6t-tKySdjqHkRIPwqhk6lcEy0wAUB8oDiBFpT1G8eAhsW-jFHHY7UBYOJXUqmgi91e2g1dmvxdQHr4M-WesD0NPTCj3IjplrykccTg8fiexbm5k9Sz3_rLPbVgZGDwcLqOp7jtDNyd0gtpZYWde04NcbTTC9WxenUpej7anaX68wzznN1RIvbAaLF4roPs0e0M7QKN03u8zEX0CFnDzniTFiNQI6vya=s64","userId":"16388542354054473882"}}},"source":["%%capture\n","!pip install mir_eval"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"TDENfLWb_7D9","executionInfo":{"status":"ok","timestamp":1624035186155,"user_tz":300,"elapsed":3125,"user":{"displayName":"JOSE ALBERTO ARANGO SÁNCHEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLxNP2GGLDngTSyVoX3tPmWhP9lveqt_TTiVGNB1jwCqiDVEMsi_RA24JdUWWb3Y1wlKlv16oda_8IGBBsSsKV_GrzfRIEv6TW3p_edCCedZVLOa8ev3I6uA5qc3a6pMNzua1Hl7mNmly5JUSWTZTSI07C3XZ1htt6oSYEcDj24zcHjj2JsmyCVMtd04XJq5Fjs2sB7BZTesrRrbzXfoZlohZtRqzFlZWu-Q5xKfoMhpUiogwnNerzSEK9Rk6MlwZN0T18dZizvT-eEqW12g1iuKj7e5zKLQVoMtnU6AzffMH-MjIxUfxYFU57d5zJBGF26z674EZkRmuHXXUZTPU6lKU-qNX59fd6OFjLnMTSGuap7iYW_o1ZUQEXiFKUWXQGWdNc1_0hj7xPF7fjYDBJZxnSPxeeIR9U0X7fXONBgqKAy32hQ8V-nGCY62PZRtjDFwi4nFVIok6_jGtiqFQK3FnNZ7zhJnDxhjDITy7LeXt0hBELVT-qB_9e38FZHnhSekkW15x_AFITdh_GUxCjoftPD8Gwi1RWAARCI6t-tKySdjqHkRIPwqhk6lcEy0wAUB8oDiBFpT1G8eAhsW-jFHHY7UBYOJXUqmgi91e2g1dmvxdQHr4M-WesD0NPTCj3IjplrykccTg8fiexbm5k9Sz3_rLPbVgZGDwcLqOp7jtDNyd0gtpZYWde04NcbTTC9WxenUpej7anaX68wzznN1RIvbAaLF4roPs0e0M7QKN03u8zEX0CFnDzniTFiNQI6vya=s64","userId":"16388542354054473882"}}},"source":["%%capture\n","!pip install pyloudnorm"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"C3_LvrEe1a8A","executionInfo":{"status":"ok","timestamp":1624035198637,"user_tz":300,"elapsed":12489,"user":{"displayName":"JOSE ALBERTO ARANGO SÁNCHEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLxNP2GGLDngTSyVoX3tPmWhP9lveqt_TTiVGNB1jwCqiDVEMsi_RA24JdUWWb3Y1wlKlv16oda_8IGBBsSsKV_GrzfRIEv6TW3p_edCCedZVLOa8ev3I6uA5qc3a6pMNzua1Hl7mNmly5JUSWTZTSI07C3XZ1htt6oSYEcDj24zcHjj2JsmyCVMtd04XJq5Fjs2sB7BZTesrRrbzXfoZlohZtRqzFlZWu-Q5xKfoMhpUiogwnNerzSEK9Rk6MlwZN0T18dZizvT-eEqW12g1iuKj7e5zKLQVoMtnU6AzffMH-MjIxUfxYFU57d5zJBGF26z674EZkRmuHXXUZTPU6lKU-qNX59fd6OFjLnMTSGuap7iYW_o1ZUQEXiFKUWXQGWdNc1_0hj7xPF7fjYDBJZxnSPxeeIR9U0X7fXONBgqKAy32hQ8V-nGCY62PZRtjDFwi4nFVIok6_jGtiqFQK3FnNZ7zhJnDxhjDITy7LeXt0hBELVT-qB_9e38FZHnhSekkW15x_AFITdh_GUxCjoftPD8Gwi1RWAARCI6t-tKySdjqHkRIPwqhk6lcEy0wAUB8oDiBFpT1G8eAhsW-jFHHY7UBYOJXUqmgi91e2g1dmvxdQHr4M-WesD0NPTCj3IjplrykccTg8fiexbm5k9Sz3_rLPbVgZGDwcLqOp7jtDNyd0gtpZYWde04NcbTTC9WxenUpej7anaX68wzznN1RIvbAaLF4roPs0e0M7QKN03u8zEX0CFnDzniTFiNQI6vya=s64","userId":"16388542354054473882"}}},"source":["%%capture\n","!pip install neptune-client"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vier96lb4Dv6"},"source":["# SepFormer\n","\n","[ATTENTION IS ALL YOU NEED IN SPEECH SEPARATION](https://arxiv.org/pdf/2010.13154.pdf)\n","\n","\n","\n","1.   [Speech Brain](https://github.com/speechbrain/speechbrain)\n","2. [Modelo Pretrained](https://huggingface.co/speechbrain/sepformer-wsj02mix)\n","3. [Separation](https://github.com/speechbrain/speechbrain/tree/develop/recipes/WSJ0Mix/separation)\n","4. [Train](https://github.com/speechbrain/speechbrain/blob/f8abef6815d483fe2208df5f41055d73c7ddc3f7/recipes/WSJ0Mix/separation/train.py)\n","5. [Config o SepFormer.py](https://github.com/speechbrain/speechbrain/blob/develop/recipes/WSJ0Mix/separation/hparams/sepformer.yaml)\n","6.[pretrained](https://github.com/speechbrain/speechbrain/blob/develop/speechbrain/pretrained/interfaces.py)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zvE_6nFN37KJ","executionInfo":{"status":"ok","timestamp":1624046865733,"user_tz":300,"elapsed":34639,"user":{"displayName":"JOSE ALBERTO ARANGO SÁNCHEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLxNP2GGLDngTSyVoX3tPmWhP9lveqt_TTiVGNB1jwCqiDVEMsi_RA24JdUWWb3Y1wlKlv16oda_8IGBBsSsKV_GrzfRIEv6TW3p_edCCedZVLOa8ev3I6uA5qc3a6pMNzua1Hl7mNmly5JUSWTZTSI07C3XZ1htt6oSYEcDj24zcHjj2JsmyCVMtd04XJq5Fjs2sB7BZTesrRrbzXfoZlohZtRqzFlZWu-Q5xKfoMhpUiogwnNerzSEK9Rk6MlwZN0T18dZizvT-eEqW12g1iuKj7e5zKLQVoMtnU6AzffMH-MjIxUfxYFU57d5zJBGF26z674EZkRmuHXXUZTPU6lKU-qNX59fd6OFjLnMTSGuap7iYW_o1ZUQEXiFKUWXQGWdNc1_0hj7xPF7fjYDBJZxnSPxeeIR9U0X7fXONBgqKAy32hQ8V-nGCY62PZRtjDFwi4nFVIok6_jGtiqFQK3FnNZ7zhJnDxhjDITy7LeXt0hBELVT-qB_9e38FZHnhSekkW15x_AFITdh_GUxCjoftPD8Gwi1RWAARCI6t-tKySdjqHkRIPwqhk6lcEy0wAUB8oDiBFpT1G8eAhsW-jFHHY7UBYOJXUqmgi91e2g1dmvxdQHr4M-WesD0NPTCj3IjplrykccTg8fiexbm5k9Sz3_rLPbVgZGDwcLqOp7jtDNyd0gtpZYWde04NcbTTC9WxenUpej7anaX68wzznN1RIvbAaLF4roPs0e0M7QKN03u8zEX0CFnDzniTFiNQI6vya=s64","userId":"16388542354054473882"}},"outputId":"48ba0eb2-a71c-49be-b21b-3d1dae5c80cb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FvYbnaM_3_Ow","executionInfo":{"status":"ok","timestamp":1624046867858,"user_tz":300,"elapsed":2128,"user":{"displayName":"JOSE ALBERTO ARANGO SÁNCHEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLxNP2GGLDngTSyVoX3tPmWhP9lveqt_TTiVGNB1jwCqiDVEMsi_RA24JdUWWb3Y1wlKlv16oda_8IGBBsSsKV_GrzfRIEv6TW3p_edCCedZVLOa8ev3I6uA5qc3a6pMNzua1Hl7mNmly5JUSWTZTSI07C3XZ1htt6oSYEcDj24zcHjj2JsmyCVMtd04XJq5Fjs2sB7BZTesrRrbzXfoZlohZtRqzFlZWu-Q5xKfoMhpUiogwnNerzSEK9Rk6MlwZN0T18dZizvT-eEqW12g1iuKj7e5zKLQVoMtnU6AzffMH-MjIxUfxYFU57d5zJBGF26z674EZkRmuHXXUZTPU6lKU-qNX59fd6OFjLnMTSGuap7iYW_o1ZUQEXiFKUWXQGWdNc1_0hj7xPF7fjYDBJZxnSPxeeIR9U0X7fXONBgqKAy32hQ8V-nGCY62PZRtjDFwi4nFVIok6_jGtiqFQK3FnNZ7zhJnDxhjDITy7LeXt0hBELVT-qB_9e38FZHnhSekkW15x_AFITdh_GUxCjoftPD8Gwi1RWAARCI6t-tKySdjqHkRIPwqhk6lcEy0wAUB8oDiBFpT1G8eAhsW-jFHHY7UBYOJXUqmgi91e2g1dmvxdQHr4M-WesD0NPTCj3IjplrykccTg8fiexbm5k9Sz3_rLPbVgZGDwcLqOp7jtDNyd0gtpZYWde04NcbTTC9WxenUpej7anaX68wzznN1RIvbAaLF4roPs0e0M7QKN03u8zEX0CFnDzniTFiNQI6vya=s64","userId":"16388542354054473882"}},"outputId":"69157ce1-4df3-45c1-cf6a-c9998506337e"},"source":["%cd /content/drive/Shareddrives/TG-Separación-Fuentes/code/train-speech-separation-models/train"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/content/drive/Shareddrives/TG-Separación-Fuentes/code/train-speech-separation-models/train\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fZNHLGY1uz4a","executionInfo":{"status":"ok","timestamp":1624046867858,"user_tz":300,"elapsed":8,"user":{"displayName":"JOSE ALBERTO ARANGO SÁNCHEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLxNP2GGLDngTSyVoX3tPmWhP9lveqt_TTiVGNB1jwCqiDVEMsi_RA24JdUWWb3Y1wlKlv16oda_8IGBBsSsKV_GrzfRIEv6TW3p_edCCedZVLOa8ev3I6uA5qc3a6pMNzua1Hl7mNmly5JUSWTZTSI07C3XZ1htt6oSYEcDj24zcHjj2JsmyCVMtd04XJq5Fjs2sB7BZTesrRrbzXfoZlohZtRqzFlZWu-Q5xKfoMhpUiogwnNerzSEK9Rk6MlwZN0T18dZizvT-eEqW12g1iuKj7e5zKLQVoMtnU6AzffMH-MjIxUfxYFU57d5zJBGF26z674EZkRmuHXXUZTPU6lKU-qNX59fd6OFjLnMTSGuap7iYW_o1ZUQEXiFKUWXQGWdNc1_0hj7xPF7fjYDBJZxnSPxeeIR9U0X7fXONBgqKAy32hQ8V-nGCY62PZRtjDFwi4nFVIok6_jGtiqFQK3FnNZ7zhJnDxhjDITy7LeXt0hBELVT-qB_9e38FZHnhSekkW15x_AFITdh_GUxCjoftPD8Gwi1RWAARCI6t-tKySdjqHkRIPwqhk6lcEy0wAUB8oDiBFpT1G8eAhsW-jFHHY7UBYOJXUqmgi91e2g1dmvxdQHr4M-WesD0NPTCj3IjplrykccTg8fiexbm5k9Sz3_rLPbVgZGDwcLqOp7jtDNyd0gtpZYWde04NcbTTC9WxenUpej7anaX68wzznN1RIvbAaLF4roPs0e0M7QKN03u8zEX0CFnDzniTFiNQI6vya=s64","userId":"16388542354054473882"}}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"h5uaPt364INS","colab":{"base_uri":"https://localhost:8080/","height":395},"executionInfo":{"status":"error","timestamp":1623944748047,"user_tz":300,"elapsed":3218,"user":{"displayName":"JOSE ALBERTO ARANGO SÁNCHEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLCm6f2qe_Gicbo3Ab1Omz1W3TtEFtmxTRMcn6uI-MGZ-LGh53BKGlBoMjD8vyMHLdZgNXbZ5jB8BwPzDRGfx8-0sttLYP9mUnE0qdb91j2Hiti3auIpWekwD06lzZibqiVQj5kkupF0sSj8CA8MimBvmvmQBYAFqUGdCBDxHvmmi2TM-dv5OqxjZOEdeKVkFCtrF6Stu-oEyAshHe_fbMLMenyTnnpoo91iCRld0fAdbmKT5aXkRSARJPDBtuXwLFBkN8yXuqbgxuhEVCsO2pdrR2rVcu-fRUpIGalEutXFszH9o-z-N6bQPKt7ntC15dOUWhdyufVvf94UBwar9WyCfzpJfuH4U1iPVGDZRN4r4qJvTKtgNL6gu6sCQ8F0zM4wJK7flef8mITW_JZ4QhWX5mmolHBI7e63Rv5-oj9N6KB-CT3ATfIIiLbh5tvGRR7oXLCky4syR18QTM6Vv7BySpMpZbwvD7OnNzDbrK1jt8Wqdj1DDZ42ZePtuFlX4V-H_ovxrvvA_lgBlhPKnTCUBTnKrXtAYdWXDnGy3OPp0XZKFqOJTVtkqsIZ85cs7qLVzNYv0lj6L9iCpnAPA3-f0elXt7UytFmIRDSvhFKPVddg2Q8ND0VqUMJyfz2z-bfTFOEMwpO7MIm4hNWmA2kLb2db2R3vJE_pYNErl38mfh7e_4cH6GbK3MfyTNNGoDsVJ4qhKwQevKOKSelW_Spt4kAm91kOhU3pmNNyEctpF9YCs0CDLxCqdOMMBOBOFH12sq=s64","userId":"16388542354054473882"}},"outputId":"20455fe0-08a7-4b5f-8a11-2c686bad39db"},"source":["from IPython.display import display, Audio\n","from speechbrain.pretrained import SepformerSeparation as separator\n","import torchaudio\n","import os\n","import sys\n","import torch\n","import torch.nn.functional as F\n","import torchaudio\n","import speechbrain as sb\n","import speechbrain.nnet.schedulers as schedulers\n","from speechbrain.utils.distributed import run_on_main\n","from torch.cuda.amp import autocast\n","from hyperpyyaml import load_hyperpyyaml\n","import numpy as np\n","from tqdm import tqdm\n","import csv\n","import logging"],"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-ea163cc1b940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSepformerSeparation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \"\"\"\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_experiment_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malignment\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataio\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistributedDataParallel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mDDP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhyperpyyaml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresolve_references\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_on_main\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSaveableDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistributedSamplerWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0m__all__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/utils/metric_stats.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mundo_padding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medit_distance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwer_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwer_details_for_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_wer_summary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_alignments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/dataio/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0m__all__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/dataio/preprocess.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspeech_augmentation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/processing/speech_augmentation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtendedCSVDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m from speechbrain.processing.signal_processing import (\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/dataio/legacy.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"SpeechBrain Extended CSV Compatibility.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDynamicItemDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/dataio/dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_pipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspeechbrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_data_csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/dataio/dataio.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchaudio/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextension\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_mod_utils\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m from torchaudio import (\n\u001b[1;32m      4\u001b[0m     \u001b[0mcompliance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchaudio/extension/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0m_init_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_init_extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchaudio/extension/extension.py\u001b[0m in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'torchaudio._torchaudio'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_mod_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_module_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0m_init_script_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torchaudio\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchaudio/extension/extension.py\u001b[0m in \u001b[0;36m_init_script_module\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_init_script_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_classes.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mshared\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0mto\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \"\"\"\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# The classes \"namespace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.7/dist-packages/torchaudio/_torchaudio.so: undefined symbol: _ZN2at6detail10noopDeleteEPv"]}]},{"cell_type":"markdown","metadata":{"id":"5qr2WJRMVgte"},"source":["# 0. Configurar Paths"]},{"cell_type":"code","metadata":{"id":"v-OJidI17XVf","executionInfo":{"status":"ok","timestamp":1624046867859,"user_tz":300,"elapsed":7,"user":{"displayName":"JOSE ALBERTO ARANGO SÁNCHEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLxNP2GGLDngTSyVoX3tPmWhP9lveqt_TTiVGNB1jwCqiDVEMsi_RA24JdUWWb3Y1wlKlv16oda_8IGBBsSsKV_GrzfRIEv6TW3p_edCCedZVLOa8ev3I6uA5qc3a6pMNzua1Hl7mNmly5JUSWTZTSI07C3XZ1htt6oSYEcDj24zcHjj2JsmyCVMtd04XJq5Fjs2sB7BZTesrRrbzXfoZlohZtRqzFlZWu-Q5xKfoMhpUiogwnNerzSEK9Rk6MlwZN0T18dZizvT-eEqW12g1iuKj7e5zKLQVoMtnU6AzffMH-MjIxUfxYFU57d5zJBGF26z674EZkRmuHXXUZTPU6lKU-qNX59fd6OFjLnMTSGuap7iYW_o1ZUQEXiFKUWXQGWdNc1_0hj7xPF7fjYDBJZxnSPxeeIR9U0X7fXONBgqKAy32hQ8V-nGCY62PZRtjDFwi4nFVIok6_jGtiqFQK3FnNZ7zhJnDxhjDITy7LeXt0hBELVT-qB_9e38FZHnhSekkW15x_AFITdh_GUxCjoftPD8Gwi1RWAARCI6t-tKySdjqHkRIPwqhk6lcEy0wAUB8oDiBFpT1G8eAhsW-jFHHY7UBYOJXUqmgi91e2g1dmvxdQHr4M-WesD0NPTCj3IjplrykccTg8fiexbm5k9Sz3_rLPbVgZGDwcLqOp7jtDNyd0gtpZYWde04NcbTTC9WxenUpej7anaX68wzznN1RIvbAaLF4roPs0e0M7QKN03u8zEX0CFnDzniTFiNQI6vya=s64","userId":"16388542354054473882"}}},"source":["# Save checkpoints\n","default_root_dir = \"/content/drive/Shareddrives/TG-Separación-Fuentes/code/Checkpoints-separation-models/SepFormer/\"\n","save_best_model = \"/content/drive/Shareddrives/TG-Separación-Fuentes/code/Checkpoints-separation-models/SepFormer/best_model/\"\n","model_path = default_root_dir+'sepformer-wsj02mix/'\n","savedir = model_path+\"Examples/\""],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"kUsO98H-4j2b","executionInfo":{"status":"ok","timestamp":1624046877447,"user_tz":300,"elapsed":653,"user":{"displayName":"JOSE ALBERTO ARANGO SÁNCHEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLxNP2GGLDngTSyVoX3tPmWhP9lveqt_TTiVGNB1jwCqiDVEMsi_RA24JdUWWb3Y1wlKlv16oda_8IGBBsSsKV_GrzfRIEv6TW3p_edCCedZVLOa8ev3I6uA5qc3a6pMNzua1Hl7mNmly5JUSWTZTSI07C3XZ1htt6oSYEcDj24zcHjj2JsmyCVMtd04XJq5Fjs2sB7BZTesrRrbzXfoZlohZtRqzFlZWu-Q5xKfoMhpUiogwnNerzSEK9Rk6MlwZN0T18dZizvT-eEqW12g1iuKj7e5zKLQVoMtnU6AzffMH-MjIxUfxYFU57d5zJBGF26z674EZkRmuHXXUZTPU6lKU-qNX59fd6OFjLnMTSGuap7iYW_o1ZUQEXiFKUWXQGWdNc1_0hj7xPF7fjYDBJZxnSPxeeIR9U0X7fXONBgqKAy32hQ8V-nGCY62PZRtjDFwi4nFVIok6_jGtiqFQK3FnNZ7zhJnDxhjDITy7LeXt0hBELVT-qB_9e38FZHnhSekkW15x_AFITdh_GUxCjoftPD8Gwi1RWAARCI6t-tKySdjqHkRIPwqhk6lcEy0wAUB8oDiBFpT1G8eAhsW-jFHHY7UBYOJXUqmgi91e2g1dmvxdQHr4M-WesD0NPTCj3IjplrykccTg8fiexbm5k9Sz3_rLPbVgZGDwcLqOp7jtDNyd0gtpZYWde04NcbTTC9WxenUpej7anaX68wzznN1RIvbAaLF4roPs0e0M7QKN03u8zEX0CFnDzniTFiNQI6vya=s64","userId":"16388542354054473882"}}},"source":["PATH_DATA_ROOT = \"../../Datasets/01-Data_experimental/intermediate\"\n","MIX = PATH_DATA_ROOT+\"mix/\"\n","S_1 = PATH_DATA_ROOT+\"source_1/\"\n","S_2 = PATH_DATA_ROOT+\"source_2/\"\n","\n","# CSV\n","\n","ROOT_CSV  =\"/content/drive/Shareddrives/TG-Separación-Fuentes/code/\"\n","PATH_SEPFORMER_CSV_TRAIN = ROOT_CSV+\"SEPFORMER_mixture_train_mix_clean_callfriend_spanish_5_seconds.csv\"\n","PATH_SEPFORMER_CSV_VALID =ROOT_CSV+\"SEPFORMER_mixture_val_mix_clean_callfriend_spanish_5_seconds.csv\"\n","PATH_SEPFORMER_CSV_TEST = ROOT_CSV+\"SEPFORMER_mixture_val_mix_clean_callfriend_spanish_5_seconds.csv\"\n","\n","PATH_SEPFORMER_CSV_TEST_TEMPORAL = ROOT_CSV+\"SEPFORMER_mixture_test_mix_clean_callfriend_spanishtemporal.csv\"\n","\n","PATH_CONFIG = \"./resources/sepformer.yaml\"\n","\n","\n","df_train = pd.read_csv(PATH_SEPFORMER_CSV_TRAIN)\n","df_val = pd.read_csv(PATH_SEPFORMER_CSV_VALID)\n","df_test = pd.read_csv(PATH_SEPFORMER_CSV_TEST)\n","#df_test_temporal = pd.read_csv(PATH_SEPFORMER_CSV_TEST_TEMPORAL)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UOQp8xdJ_shO"},"source":["# 2. Configurar modelo"]},{"cell_type":"code","metadata":{"id":"JPHBHArnCpxO"},"source":["def dataio_prep(hparams):\n","    \"\"\"Creates data processing pipeline\"\"\"\n","\n","    # 1. Define datasets\n","    train_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n","        csv_path=hparams[\"train_data\"],\n","        replacements={\"data_root\": hparams[\"data_folder\"]},\n","    )\n","\n","    valid_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n","        csv_path=hparams[\"valid_data\"],\n","        replacements={\"data_root\": hparams[\"data_folder\"]},\n","    )\n","\n","    test_data = sb.dataio.dataset.DynamicItemDataset.from_csv(\n","        csv_path=hparams[\"test_data\"],\n","        replacements={\"data_root\": hparams[\"data_folder\"]},\n","    )\n","\n","    datasets = [train_data, valid_data, test_data]\n","\n","    # 2. Provide audio pipelines\n","\n","    @sb.utils.data_pipeline.takes(\"mix_wav\")\n","    @sb.utils.data_pipeline.provides(\"mix_sig\")\n","    def audio_pipeline_mix(mix_wav):\n","        mix_sig = sb.dataio.dataio.read_audio(mix_wav)\n","        return mix_sig\n","\n","    @sb.utils.data_pipeline.takes(\"s1_wav\")\n","    @sb.utils.data_pipeline.provides(\"s1_sig\")\n","    def audio_pipeline_s1(s1_wav):\n","        s1_sig = sb.dataio.dataio.read_audio(s1_wav)\n","        return s1_sig\n","\n","    @sb.utils.data_pipeline.takes(\"s2_wav\")\n","    @sb.utils.data_pipeline.provides(\"s2_sig\")\n","    def audio_pipeline_s2(s2_wav):\n","        s2_sig = sb.dataio.dataio.read_audio(s2_wav)\n","        return s2_sig\n","\n","    if hparams[\"num_spks\"] == 3:\n","\n","        @sb.utils.data_pipeline.takes(\"s3_wav\")\n","        @sb.utils.data_pipeline.provides(\"s3_sig\")\n","        def audio_pipeline_s3(s3_wav):\n","            s3_sig = sb.dataio.dataio.read_audio(s3_wav)\n","            return s3_sig\n","\n","    if \"wham\" in hparams[\"data_folder\"]:\n","\n","        @sb.utils.data_pipeline.takes(\"noise_wav\")\n","        @sb.utils.data_pipeline.provides(\"noise_sig\")\n","        def audio_pipeline_noise(noise_wav):\n","            noise_sig = sb.dataio.dataio.read_audio(noise_wav)\n","            return noise_sig\n","\n","    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_mix)\n","    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s1)\n","    sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s2)\n","    if hparams[\"num_spks\"] == 3:\n","        sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_s3)\n","        sb.dataio.dataset.set_output_keys(\n","            datasets, [\"id\", \"mix_sig\", \"s1_sig\", \"s2_sig\", \"s3_sig\"]\n","        )\n","    else:\n","        if \"wham\" in hparams[\"data_folder\"]:\n","            print(\"Using the WHAM! dataset\")\n","            sb.dataio.dataset.add_dynamic_item(datasets, audio_pipeline_noise)\n","            sb.dataio.dataset.set_output_keys(\n","                datasets, [\"id\", \"mix_sig\", \"s1_sig\", \"s2_sig\", \"noise_sig\"]\n","            )\n","        else:\n","            sb.dataio.dataset.set_output_keys(\n","                datasets, [\"id\", \"mix_sig\", \"s1_sig\", \"s2_sig\"]\n","            )\n","\n","    return train_data, valid_data, test_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1w7sfSsJDGGo"},"source":["# Define training procedure\n","class Separation(sb.Brain):\n","    def compute_forward(self, mix, targets, stage, noise=None):\n","        \"\"\"Forward computations from the mixture to the separated signals.\"\"\"\n","\n","        # Unpack lists and put tensors in the right device\n","        mix, mix_lens = mix\n","\n","        print(mix.shape,mix_lens.shape)\n","\n","        mix, mix_lens = mix.to(self.device), mix_lens.to(self.device)\n","\n","        # Convert targets to tensor\n","        targets = torch.cat(\n","            [targets[i][0].unsqueeze(-1) for i in range(self.hparams.num_spks)],\n","            dim=-1,\n","        ).to(self.device)\n","\n","        # Add speech distortions\n","        if stage == sb.Stage.TRAIN:\n","            with torch.no_grad():\n","                if self.hparams.use_speedperturb or self.hparams.use_rand_shift:\n","                    mix, targets = self.add_speed_perturb(targets, mix_lens)\n","\n","                    if \"whamr\" in self.hparams.data_folder:\n","                        targets = self.hparams.reverb(\n","                            targets[0].t(), torch.ones(targets.size(-1))\n","                        )\n","                        targets = targets.t().unsqueeze(0)\n","                        mix = targets.sum(-1)\n","\n","                    if \"wham\" in self.hparams.data_folder:\n","                        noise = noise.to(self.device)\n","                        len_noise = noise.shape[1]\n","                        len_mix = mix.shape[1]\n","                        min_len = min(len_noise, len_mix)\n","\n","                        # add the noise\n","                        mix = mix[:, :min_len] + noise[:, :min_len]\n","\n","                        # fix the length of targets also\n","                        targets = targets[:, :min_len, :]\n","\n","                if self.hparams.use_wavedrop:\n","                    mix = self.hparams.wavedrop(mix, mix_lens)\n","\n","                if self.hparams.limit_training_signal_len:\n","                    mix, targets = self.cut_signals(mix, targets)\n","\n","        # Separation\n","        mix_w = self.hparams.Encoder(mix)\n","        est_mask = self.hparams.MaskNet(mix_w)\n","        mix_w = torch.stack([mix_w] * self.hparams.num_spks)\n","        sep_h = mix_w * est_mask\n","\n","        # Decoding\n","        est_source = torch.cat(\n","            [\n","                self.hparams.Decoder(sep_h[i]).unsqueeze(-1)\n","                for i in range(self.hparams.num_spks)\n","            ],\n","            dim=-1,\n","        )\n","\n","        # T changed after conv1d in encoder, fix it here\n","        T_origin = mix.size(1)\n","        T_est = est_source.size(1)\n","        if T_origin > T_est:\n","            est_source = F.pad(est_source, (0, 0, 0, T_origin - T_est))\n","        else:\n","            est_source = est_source[:, :T_origin, :]\n","\n","        return est_source, targets\n","\n","    def compute_objectives(self, predictions, targets):\n","        \"\"\"Computes the sinr loss\"\"\"\n","        return self.hparams.loss(targets, predictions)\n","\n","    def fit_batch(self, batch):\n","        \"\"\"Trains one batch\"\"\"\n","        # Unpacking batch list\n","        mixture = batch.mix_sig\n","        targets = [batch.s1_sig, batch.s2_sig]\n","        if \"wham\" in self.hparams.data_folder:\n","            noise = batch.noise_sig[0]\n","        else:\n","            noise = None\n","\n","        if self.hparams.num_spks == 3:\n","            targets.append(batch.s3_sig)\n","\n","        if self.hparams.auto_mix_prec:\n","            with autocast():\n","                predictions, targets = self.compute_forward(\n","                    mixture, targets, sb.Stage.TRAIN, noise\n","                )\n","                loss = self.compute_objectives(predictions, targets)\n","\n","                # hard threshold the easy dataitems\n","                if self.hparams.threshold_byloss:\n","                    th = self.hparams.threshold\n","                    loss_to_keep = loss[loss > th]\n","                    if loss_to_keep.nelement() > 0:\n","                        loss = loss_to_keep.mean()\n","                else:\n","                    loss = loss.mean()\n","\n","            if (\n","                loss < self.hparams.loss_upper_lim and loss.nelement() > 0\n","            ):  # the fix for computational problems\n","                self.scaler.scale(loss).backward()\n","                if self.hparams.clip_grad_norm >= 0:\n","                    self.scaler.unscale_(self.optimizer)\n","                    torch.nn.utils.clip_grad_norm_(\n","                        self.modules.parameters(), self.hparams.clip_grad_norm,\n","                    )\n","                self.scaler.step(self.optimizer)\n","                self.scaler.update()\n","            else:\n","                self.nonfinite_count += 1\n","                logger.info(\n","                    \"infinite loss or empty loss! it happened {} times so far - skipping this batch\".format(\n","                        self.nonfinite_count\n","                    )\n","                )\n","                loss.data = torch.tensor(0).to(self.device)\n","        else:\n","            predictions, targets = self.compute_forward(\n","                mixture, targets, sb.Stage.TRAIN, noise\n","            )\n","            loss = self.compute_objectives(predictions, targets)\n","\n","            if self.hparams.threshold_byloss:\n","                th = self.hparams.threshold\n","                loss_to_keep = loss[loss > th]\n","                if loss_to_keep.nelement() > 0:\n","                    loss = loss_to_keep.mean()\n","            else:\n","                loss = loss.mean()\n","\n","            if (\n","                loss < self.hparams.loss_upper_lim and loss.nelement() > 0\n","            ):  # the fix for computational problems\n","                loss.backward()\n","                if self.hparams.clip_grad_norm >= 0:\n","                    torch.nn.utils.clip_grad_norm_(\n","                        self.modules.parameters(), self.hparams.clip_grad_norm\n","                    )\n","                self.optimizer.step()\n","            else:\n","                self.nonfinite_count += 1\n","                logger.info(\n","                    \"infinite loss or empty loss! it happened {} times so far - skipping this batch\".format(\n","                        self.nonfinite_count\n","                    )\n","                )\n","                loss.data = torch.tensor(0).to(self.device)\n","        self.optimizer.zero_grad()\n","\n","        return loss.detach().cpu()\n","\n","    def evaluate_batch(self, batch, stage):\n","        \"\"\"Computations needed for validation/test batches\"\"\"\n","        snt_id = batch.id\n","        mixture = batch.mix_sig\n","        targets = [batch.s1_sig, batch.s2_sig]\n","        if self.hparams.num_spks == 3:\n","            targets.append(batch.s3_sig)\n","\n","        with torch.no_grad():\n","            predictions, targets = self.compute_forward(mixture, targets, stage)\n","            loss = self.compute_objectives(predictions, targets)\n","\n","        # Manage audio file saving\n","        if stage == sb.Stage.TEST and self.hparams.save_audio:\n","            if hasattr(self.hparams, \"n_audio_to_save\"):\n","                if self.hparams.n_audio_to_save > 0:\n","                    self.save_audio(snt_id[0], mixture, targets, predictions)\n","                    self.hparams.n_audio_to_save += -1\n","            else:\n","                self.save_audio(snt_id[0], mixture, targets, predictions)\n","\n","        return loss.detach()\n","\n","    def on_stage_end(self, stage, stage_loss, epoch):\n","        \"\"\"Gets called at the end of a epoch.\"\"\"\n","        # Compute/store important stats\n","        stage_stats = {\"si-snr\": stage_loss}\n","        if stage == sb.Stage.TRAIN:\n","            self.train_stats = stage_stats\n","\n","        # Perform end-of-iteration things, like annealing, logging, etc.\n","        if stage == sb.Stage.VALID:\n","\n","            # Learning rate annealing\n","            if isinstance(\n","                self.hparams.lr_scheduler, schedulers.ReduceLROnPlateau\n","            ):\n","                current_lr, next_lr = self.hparams.lr_scheduler(\n","                    [self.optimizer], epoch, stage_loss\n","                )\n","                schedulers.update_learning_rate(self.optimizer, next_lr)\n","            else:\n","                # if we do not use the reducelronplateau, we do not change the lr\n","                current_lr = self.hparams.optimizer.optim.param_groups[0][\"lr\"]\n","\n","            self.hparams.train_logger.log_stats(\n","                stats_meta={\"epoch\": epoch, \"lr\": current_lr},\n","                train_stats=self.train_stats,\n","                valid_stats=stage_stats,\n","            )\n","            self.checkpointer.save_and_keep_only(\n","                meta={\"si-snr\": stage_stats[\"si-snr\"]}, min_keys=[\"si-snr\"],\n","            )\n","        elif stage == sb.Stage.TEST:\n","            self.hparams.train_logger.log_stats(\n","                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n","                test_stats=stage_stats,\n","            )\n","\n","    def add_speed_perturb(self, targets, targ_lens):\n","        \"\"\"Adds speed perturbation and random_shift to the input signals\"\"\"\n","\n","        min_len = -1\n","        recombine = False\n","\n","        if self.hparams.use_speedperturb:\n","            # Performing speed change (independently on each source)\n","            new_targets = []\n","            recombine = True\n","\n","            for i in range(targets.shape[-1]):\n","                new_target = self.hparams.speedperturb(\n","                    targets[:, :, i], targ_lens\n","                )\n","                new_targets.append(new_target)\n","                if i == 0:\n","                    min_len = new_target.shape[-1]\n","                else:\n","                    if new_target.shape[-1] < min_len:\n","                        min_len = new_target.shape[-1]\n","\n","            if self.hparams.use_rand_shift:\n","                # Performing random_shift (independently on each source)\n","                recombine = True\n","                for i in range(targets.shape[-1]):\n","                    rand_shift = torch.randint(\n","                        self.hparams.min_shift, self.hparams.max_shift, (1,)\n","                    )\n","                    new_targets[i] = new_targets[i].to(self.device)\n","                    new_targets[i] = torch.roll(\n","                        new_targets[i], shifts=(rand_shift[0],), dims=1\n","                    )\n","\n","            # Re-combination\n","            if recombine:\n","                if self.hparams.use_speedperturb:\n","                    targets = torch.zeros(\n","                        targets.shape[0],\n","                        min_len,\n","                        targets.shape[-1],\n","                        device=targets.device,\n","                        dtype=torch.float,\n","                    )\n","                for i, new_target in enumerate(new_targets):\n","                    targets[:, :, i] = new_targets[i][:, 0:min_len]\n","\n","        mix = targets.sum(-1)\n","        return mix, targets\n","\n","    def cut_signals(self, mixture, targets):\n","        \"\"\"This function selects a random segment of a given length within the mixture.\n","        The corresponding targets are selected accordingly\"\"\"\n","        randstart = torch.randint(\n","            0,\n","            1 + max(0, mixture.shape[1] - self.hparams.training_signal_len),\n","            (1,),\n","        ).item()\n","        targets = targets[\n","            :, randstart : randstart + self.hparams.training_signal_len, :\n","        ]\n","        mixture = mixture[\n","            :, randstart : randstart + self.hparams.training_signal_len\n","        ]\n","        return mixture, targets\n","\n","    def reset_layer_recursively(self, layer):\n","        \"\"\"Reinitializes the parameters of the neural networks\"\"\"\n","        if hasattr(layer, \"reset_parameters\"):\n","            layer.reset_parameters()\n","        for child_layer in layer.modules():\n","            if layer != child_layer:\n","                self.reset_layer_recursively(child_layer)\n","\n","    def save_results(self, test_data):\n","        \"\"\"This script computes the SDR and SI-SNR metrics and saves\n","        them into a csv file\"\"\"\n","\n","        # This package is required for SDR computation\n","        from mir_eval.separation import bss_eval_sources\n","\n","        # Create folders where to store audio\n","        save_file = os.path.join(self.hparams.output_folder, \"test_results.csv\")\n","\n","        # Variable init\n","        all_sdrs = []\n","        all_sdrs_i = []\n","        all_sisnrs = []\n","        all_sisnrs_i = []\n","        csv_columns = [\"snt_id\", \"sdr\", \"sdr_i\", \"si-snr\", \"si-snr_i\"]\n","\n","        test_loader = sb.dataio.dataloader.make_dataloader(\n","            test_data, **self.hparams.dataloader_opts\n","        )\n","\n","        with open(save_file, \"w\") as results_csv:\n","            writer = csv.DictWriter(results_csv, fieldnames=csv_columns)\n","            writer.writeheader()\n","\n","            # Loop over all test sentence\n","            with tqdm(test_loader, dynamic_ncols=True) as t:\n","                for i, batch in enumerate(t):\n","\n","                    # Apply Separation\n","                    mixture, mix_len = batch.mix_sig\n","                    snt_id = batch.id\n","                    targets = [batch.s1_sig, batch.s2_sig]\n","                    if self.hparams.num_spks == 3:\n","                        targets.append(batch.s3_sig)\n","\n","                    with torch.no_grad():\n","                        predictions, targets = self.compute_forward(\n","                            batch.mix_sig, targets, sb.Stage.TEST\n","                        )\n","\n","                    # Compute SI-SNR\n","                    sisnr = self.compute_objectives(predictions, targets)\n","\n","                    # Compute SI-SNR improvement\n","                    mixture_signal = torch.stack(\n","                        [mixture] * self.hparams.num_spks, dim=-1\n","                    )\n","                    mixture_signal = mixture_signal.to(targets.device)\n","                    sisnr_baseline = self.compute_objectives(\n","                        mixture_signal, targets\n","                    )\n","                    sisnr_i = sisnr - sisnr_baseline\n","\n","                    # Compute SDR\n","                    sdr, _, _, _ = bss_eval_sources(\n","                        targets[0].t().cpu().numpy(),\n","                        predictions[0].t().detach().cpu().numpy(),\n","                    )\n","\n","                    sdr_baseline, _, _, _ = bss_eval_sources(\n","                        targets[0].t().cpu().numpy(),\n","                        mixture_signal[0].t().detach().cpu().numpy(),\n","                    )\n","\n","                    sdr_i = sdr.mean() - sdr_baseline.mean()\n","\n","                    # Saving on a csv file\n","                    row = {\n","                        \"snt_id\": snt_id[0],\n","                        \"sdr\": sdr.mean(),\n","                        \"sdr_i\": sdr_i,\n","                        \"si-snr\": -sisnr.item(),\n","                        \"si-snr_i\": -sisnr_i.item(),\n","                    }\n","                    writer.writerow(row)\n","\n","                    # Metric Accumulation\n","                    all_sdrs.append(sdr.mean())\n","                    all_sdrs_i.append(sdr_i.mean())\n","                    all_sisnrs.append(-sisnr.item())\n","                    all_sisnrs_i.append(-sisnr_i.item())\n","\n","                row = {\n","                    \"snt_id\": \"avg\",\n","                    \"sdr\": np.array(all_sdrs).mean(),\n","                    \"sdr_i\": np.array(all_sdrs_i).mean(),\n","                    \"si-snr\": np.array(all_sisnrs).mean(),\n","                    \"si-snr_i\": np.array(all_sisnrs_i).mean(),\n","                }\n","                writer.writerow(row)\n","\n","        logger.info(\"Mean SISNR is {}\".format(np.array(all_sisnrs).mean()))\n","        logger.info(\"Mean SISNRi is {}\".format(np.array(all_sisnrs_i).mean()))\n","        logger.info(\"Mean SDR is {}\".format(np.array(all_sdrs).mean()))\n","        logger.info(\"Mean SDRi is {}\".format(np.array(all_sdrs_i).mean()))\n","\n","\n","    def save_audio(self, snt_id, mixture, targets, predictions):\n","        \"saves the test audio (mixture, targets, and estimated sources) on disk\"\n","\n","        # Create outout folder\n","        save_path = os.path.join(self.hparams.save_folder, \"audio_results\")\n","        if not os.path.exists(save_path):\n","            os.mkdir(save_path)\n","\n","        for ns in range(self.hparams.num_spks):\n","\n","            # Estimated source\n","            signal = predictions[0, :, ns]\n","            signal = signal / signal.abs().max()\n","            save_file = os.path.join(\n","                save_path, \"item{}_source{}hat.wav\".format(snt_id, ns + 1)\n","            )\n","            torchaudio.save(\n","                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n","            )\n","\n","            # Original source\n","            signal = targets[0, :, ns]\n","            signal = signal / signal.abs().max()\n","            save_file = os.path.join(\n","                save_path, \"item{}_source{}.wav\".format(snt_id, ns + 1)\n","            )\n","            torchaudio.save(\n","                save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n","            )\n","\n","        # Mixture\n","        signal = mixture[0][0, :]\n","        signal = signal / signal.abs().max()\n","        save_file = os.path.join(save_path, \"item{}_mix.wav\".format(snt_id))\n","        torchaudio.save(\n","            save_file, signal.unsqueeze(0).cpu(), self.hparams.sample_rate\n","        )   \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WQbKVc7lVPB4"},"source":["# 3. Parametros"]},{"cell_type":"code","metadata":{"id":"Pq885b5JVAhr"},"source":["argv = ['/content/drive/Shareddrives/TG-Separación-Fuentes/code/train-speech-separation-models/train/resources/sepformer.yaml']\n","hparams_file, run_opts, overrides = sb.parse_arguments(argv)\n","with open(hparams_file) as fin:\n","    hparams = load_hyperpyyaml(fin, overrides)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dwID1hH8gbj4","executionInfo":{"elapsed":7,"status":"ok","timestamp":1623362579594,"user":{"displayName":"JOSE ALBERTO ARANGO SÁNCHEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhK8OL1D08vaVB_t0FTDT_mcF24nbNLsD6OxGIu4JdOMpWf-7RzJ90oOJXbENuif8NfEo7jcks88CTkyGuYY9wUTk8A1EBmnUu0dtsZOnDEPkSeDSE5hhyHvbkIWoJQm0W3rlCDBPKvcnPi-aLp0BoRjUmB2JBurPDOvhGgpRx-22iCDkVpDF5lznMdFc60_mYoAal1YBvmTHc8hxLDwDvC0hmpNOx6OBwAB-r6JkpztzGaszPe2DIYb5LVYB0jQeZFbDjkEx6RjJINk5TItjkSf98XJ2D_UDZdV3Q0wFO2B-IYTJxMCl8cUB9t0jb8KHjY65YuEX4xP1tDbDsqSPa_m90pnrYhWBYvzP1dO6QNCtZufS0ogLo_rxXk-1JgNtNLZ3u2_WfPqs06lfFXh7DCrgEoqglTa2h4Z1Rz8FUiRMTyWX_tw2OWfGOTp9Rq6Zl4D2EeyebtnaAtbpb24OEDCmBmHHBmyMsrbVjO32sJeI4o-i9BN8BpwdqRmE1Fqbd7UyjqQNv-dfy2L_kA4lu9DdL0PdM0TZSsfpddS_h5JcDiRR9Ld-BgBEOqO2HK5geCNbhvDplbt9AwxyXx5xwre-yoksc9DgPW5wtePDX9YlSY3NwJqmt9rv7Fu_pJACmUDFiBgo97jHOF8kWB0yFyVxcpFSjLdRkt9l8E69Ghke_B0NyI1nRssgmyDup0UgjaqxnPa8qVleMw85yddUIqmZT03yfMwdZ-whm1dV1Fzip2Yp39PC7eqv7nPiMAZ47SZ5Oy=s64","userId":"16388542354054473882"},"user_tz":300},"outputId":"498ab24a-5653-4310-e335-8b2ff1b46ee7"},"source":["hparams[\"dataloader_opts\"][\"batch_size\"]=1\n","hparams[\"dataloader_opts\"][\"num_workers\"]=1\n","\n","hparams[\"dataloader_opts\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'batch_size': 1, 'num_workers': 1}"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"aijWCd5OVTx9"},"source":["# 4. DataLoaders"]},{"cell_type":"code","metadata":{"id":"RWE2qvd6Ekzv"},"source":["train_data, valid_data, test_data = dataio_prep(hparams)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oWerT6fEcfNZ","executionInfo":{"elapsed":16,"status":"ok","timestamp":1623362590872,"user":{"displayName":"JOSE ALBERTO ARANGO SÁNCHEZ","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhK8OL1D08vaVB_t0FTDT_mcF24nbNLsD6OxGIu4JdOMpWf-7RzJ90oOJXbENuif8NfEo7jcks88CTkyGuYY9wUTk8A1EBmnUu0dtsZOnDEPkSeDSE5hhyHvbkIWoJQm0W3rlCDBPKvcnPi-aLp0BoRjUmB2JBurPDOvhGgpRx-22iCDkVpDF5lznMdFc60_mYoAal1YBvmTHc8hxLDwDvC0hmpNOx6OBwAB-r6JkpztzGaszPe2DIYb5LVYB0jQeZFbDjkEx6RjJINk5TItjkSf98XJ2D_UDZdV3Q0wFO2B-IYTJxMCl8cUB9t0jb8KHjY65YuEX4xP1tDbDsqSPa_m90pnrYhWBYvzP1dO6QNCtZufS0ogLo_rxXk-1JgNtNLZ3u2_WfPqs06lfFXh7DCrgEoqglTa2h4Z1Rz8FUiRMTyWX_tw2OWfGOTp9Rq6Zl4D2EeyebtnaAtbpb24OEDCmBmHHBmyMsrbVjO32sJeI4o-i9BN8BpwdqRmE1Fqbd7UyjqQNv-dfy2L_kA4lu9DdL0PdM0TZSsfpddS_h5JcDiRR9Ld-BgBEOqO2HK5geCNbhvDplbt9AwxyXx5xwre-yoksc9DgPW5wtePDX9YlSY3NwJqmt9rv7Fu_pJACmUDFiBgo97jHOF8kWB0yFyVxcpFSjLdRkt9l8E69Ghke_B0NyI1nRssgmyDup0UgjaqxnPa8qVleMw85yddUIqmZT03yfMwdZ-whm1dV1Fzip2Yp39PC7eqv7nPiMAZ47SZ5Oy=s64","userId":"16388542354054473882"},"user_tz":300},"outputId":"133c6588-e42d-4b4c-da09-416630446ccf"},"source":["len(train_data),len(test_data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(280714, 5)"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"WB6Zy9JhVXc7"},"source":["# 5. Modelo"]},{"cell_type":"code","metadata":{"id":"H-DuSyVSE54H"},"source":["# Brain class initialization\n","separator = Separation(\n","    modules=hparams[\"modules\"],\n","    opt_class=hparams[\"optimizer\"],\n","    hparams=hparams,\n","    run_opts=run_opts,\n","    checkpointer=hparams[\"checkpointer\"],\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BbmsMBFqFDri"},"source":["# re-initialize the parameters\n","for module in separator.modules.values():\n","    separator.reset_layer_recursively(module)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SHOuMNUlVt_B"},"source":["# 6. Train"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"Qxb30q1RFNN3","outputId":"93f633c2-f4e1-4562-e869-c9f480c48551"},"source":["if not hparams[\"test_only\"]:\n","  # Training\n","  separator.fit(\n","      separator.hparams.epoch_counter,\n","      train_data,\n","      valid_data,\n","      train_loader_kwargs=hparams[\"dataloader_opts\"],\n","      valid_loader_kwargs=hparams[\"dataloader_opts\"],\n","  )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/280714 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([1, 120000]) torch.Size([1])\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/280714 [03:14<?, ?it/s]\n"],"name":"stderr"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-03c8a4835979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mtrain_loader_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataloader_opts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mvalid_loader_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataloader_opts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epoch_counter, train_set, valid_set, progressbar, train_loader_kwargs, valid_loader_kwargs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m                     self.avg_train_loss = self.update_average(\n\u001b[1;32m   1015\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_train_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-a3e23bafab3b>\u001b[0m in \u001b[0;36mfit_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             predictions, targets = self.compute_forward(\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0mmixture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             )\n\u001b[1;32m    131\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_objectives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-a3e23bafab3b>\u001b[0m in \u001b[0;36mcompute_forward\u001b[0;34m(self, mix, targets, stage, noise)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Separation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mmix_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mest_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmix_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mmix_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmix_w\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_spks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0msep_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmix_w\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mest_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/lobes/models/dual_path.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# [B, N, K, S]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_mdl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/lobes/models/dual_path.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0;31m# [BS, K, H]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m         \u001b[0mintra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintra_mdl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;31m# [BS, K, N]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/lobes/models/dual_path.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_positional_encoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mpos_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmdl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/lobes/models/transformer/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             )\n\u001b[1;32m    382\u001b[0m             \u001b[0mattention_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/lobes/models/transformer/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0msrc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_ffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;31m# add & norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/speechbrain/nnet/attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# give a tensor of shap (time, batch, fea)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m# reshape the output back to (batch, time, fea)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 15.90 GiB total capacity; 14.86 GiB already allocated; 121.75 MiB free; 14.90 GiB reserved in total by PyTorch)"]}]}]}