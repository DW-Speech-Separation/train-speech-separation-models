{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PyTorch Lightning + Neptune.ipynb","provenance":[{"file_id":"https://github.com/neptune-ai/neptune-colab-examples/blob/master/pytorch_lightning-integration.ipynb","timestamp":1620511456675}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QXGSKS1u0n8x"},"source":["# PyTorch Lightning + Neptune\n","\n","Neptune helps you keep track of your machine learning experiments and if you are using PyTorch Lightning you can add tracking very easily. \n","\n","Let me show you how.\n","\n","### Install dependencies \n","\n","Not all of those are a must but I wanted to show more cool stuff."]},{"cell_type":"code","metadata":{"id":"DO7yawFVxVIt"},"source":["pip install pytorch-lightning scikit-plot neptune-client neptune-contrib[viz] --upgrade"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rf3FmHL11R0r"},"source":["# Basic Example\n","\n","## Define LightningModule\n","\n","This is your typical `pl.LightningModule` with required methods defined. Nothing new here."]},{"cell_type":"code","metadata":{"id":"ljhFSnypxdUW"},"source":["import os\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import torch\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import MNIST\n","from torchvision import transforms\n","\n","import pytorch_lightning as pl\n","\n","MAX_EPOCHS=3\n","LR=0.02\n","BATCHSIZE=32\n","\n","class BasicSystem(pl.LightningModule):\n","\n","    def __init__(self):\n","        super(BasicSystem, self).__init__()\n","        # not the best model...\n","        self.l1 = torch.nn.Linear(28 * 28, 10)\n","\n","    def forward(self, x):\n","        return torch.relu(self.l1(x.view(x.size(0), -1)))\n","\n","    def training_step(self, batch, batch_idx):\n","        # REQUIRED\n","        x, y = batch\n","        y_hat = self.forward(x)\n","        loss = F.cross_entropy(y_hat, y)\n","        tensorboard_logs = {'train_loss': loss}\n","        return {'loss': loss, 'log': tensorboard_logs}\n","\n","    def configure_optimizers(self):\n","        # REQUIRED\n","        # can return multiple optimizers and learning_rate schedulers\n","        # (LBFGS it is automatically supported, no need for closure function)\n","        return torch.optim.Adam(self.parameters(), lr=LR)\n","\n","    @pl.data_loader\n","    def train_dataloader(self):\n","        # REQUIRED\n","        return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=BATCHSIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AW4MM4qj5ErX"},"source":["## Create NeptuneLogger\n","\n","`NeptuneLogger` is your connection to [Neptune service](https://neptune.ai). \n","\n","You need to specify your `api_token` and decide to which project you want to track your experiments by defining `project_name`.\n","\n","In this tutorial, I will use an open project \"shared/pytoch-lightning-integration\" and a token that belongs to the anonymous user \"neptuner\"."]},{"cell_type":"code","metadata":{"id":"GvDSBSrOx-R4"},"source":["from pytorch_lightning.loggers.neptune import NeptuneLogger\n","\n","neptune_logger = NeptuneLogger(\n","    api_key=\"ANONYMOUS\",\n","    project_name=\"shared/pytorch-lightning-integration\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UphOuRMm5sZs"},"source":["## Pass neptune_logger to Trainer\n","\n","Now that you have your neptune_logger instantiated you simply need to pass it to the `Trainer`and run your .fit loop."]},{"cell_type":"code","metadata":{"id":"3u_Kb86BzWzq"},"source":["from pytorch_lightning import Trainer\n","\n","basic_model = BasicSystem()\n","trainer = Trainer(max_epochs=MAX_EPOCHS,\n","                  logger=neptune_logger,\n","                  )\n","trainer.fit(basic_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ta6VcI8z6DvM"},"source":["## Explore your experiments in Neptune\n","\n","With just a few lines of code you get:\n","\n","\n","* metrics logged and charts created\n","* hyperparameters logged (if passed via hparams)\n","* hardware monitoring\n","* git info and execution script snapshoted and saved\n","\n","Click on the link that was outputed to the console or [go here](https://ui.neptune.ai/o/shared/org/pytorch-lightning-integration/e/PYTOR-121) to explore your experiment. \n","\n","It will look somewhat like thsi one:\n","\n","![image](https://neptune.ai/wp-content/uploads/lightning_basic.gif)\n","\n","but there are way more things you can take advantage of if you add just a few more lines. \n","\n","Let me show you what I mean.\n","\n","# Advanced Example\n","\n","## Log custom objects during training\n","\n","You can log:\n","\n","* additional metrics\n","* images and charts\n","* artifacts like model checkpoints during training.\n","\n","All you need to do is define what you want to log inside of one of the iteration loop methods.\n","\n","For example, let's log histogram of validation losses after every epoch.\n","To do that we will access `self.logger.experiment` during `validation_end` call and use the `.log_image` method from Neptune. \n","\n","```python\n","    def validation_end(self, outputs):\n","        # OPTIONAL\n","        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n","        tensorboard_logs = {'val_loss': avg_loss}\n","\n","        fig = plt.figure()\n","        losses = np.stack([x['val_loss'].numpy() for x in outputs])\n","        plt.hist(losses)\n","        self.logger.experiment.log_image('loss_histograms', fig)\n","\n","        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n","```\n","\n","Let's create a `pl.LightningModule` to see how it works."]},{"cell_type":"code","metadata":{"id":"g85_mosnxz56"},"source":["MAX_EPOCHS=7\n","LR=0.02\n","BATCHSIZE=32\n","CHECKPOINTS_DIR = 'my_models/checkpoints/'\n","\n","class AdvancedSystem(BasicSystem):\n","\n","    def validation_step(self, batch, batch_idx):\n","        # OPTIONAL\n","        x, y = batch\n","        y_hat = self.forward(x)\n","        return {'val_loss': F.cross_entropy(y_hat, y)}\n","\n","    def validation_end(self, outputs):\n","        # OPTIONAL\n","        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n","        tensorboard_logs = {'val_loss': avg_loss}\n","\n","        fig = plt.figure()\n","        losses = np.stack([x['val_loss'].numpy() for x in outputs])\n","        plt.hist(losses)\n","        self.logger.experiment.log_image('loss_histograms', fig)\n","        plt.close(fig)\n","\n","        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}\n","\n","    def test_step(self, batch, batch_idx):\n","        # OPTIONAL\n","        x, y = batch\n","        y_hat = self.forward(x)\n","        return {'test_loss': F.cross_entropy(y_hat, y)}\n","\n","    def test_end(self, outputs):\n","        # OPTIONAL\n","        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n","        tensorboard_logs = {'test_loss': avg_loss}\n","        return {'avg_test_loss': avg_loss, 'log': tensorboard_logs}\n","\n","    @pl.data_loader\n","    def val_dataloader(self):\n","        # OPTIONAL\n","        return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=BATCHSIZE)\n","\n","    @pl.data_loader\n","    def test_dataloader(self):\n","        # OPTIONAL\n","        return DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor()), batch_size=BATCHSIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ZMXx2rQ83Z_"},"source":["## Define NeptuneLogger with custom params\n","\n","We will also create a more advanced `NeptuneLogger` that contains information about hyperparameters, add tags to make runs organized, and define which scripts we want to snapshot.\n","\n","Also, I will use the `close_after_fit=False` argument to make sure that the logger doesn't close after the `.fit` loop ends."]},{"cell_type":"code","metadata":{"id":"hqs2hTD8yAyu"},"source":["neptune_logger = NeptuneLogger(\n","    api_key=\"ANONYMOUS\",\n","    project_name=\"shared/pytorch-lightning-integration\",\n","    close_after_fit=False,\n","    experiment_name=\"default\",  # Optional,\n","    params={\"max_epochs\": MAX_EPOCHS,\n","            \"batch_size\": BATCHSIZE,\n","            \"lr\": LR}, # Optional,\n","    tags=[\"pytorch-lightning\", \"mlp\"],\n","    upload_source_files=['*.py','*.yaml'],\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sfr85ZBm9QAw"},"source":["## Pass neptune_logger to the Trainer\n","\n","Again we need to pass `neptune_logger` to the `Trainer` object:"]},{"cell_type":"code","metadata":{"id":"Vbn5fv0Izld0"},"source":["from pytorch_lightning import Trainer\n","\n","model_checkpoint = pl.callbacks.ModelCheckpoint(filepath=CHECKPOINTS_DIR)\n","\n","advanced_model = AdvancedSystem()\n","trainer = Trainer(max_epochs=MAX_EPOCHS,\n","                  logger=neptune_logger,\n","                  checkpoint_callback=model_checkpoint,\n","                  )\n","trainer.fit(advanced_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e92BRaEZ9XZs"},"source":["and we can explore our run in Neptune.\n","\n","But since we specified `close_after_fit=False` we can log additional things like:\n","\n","### Test metrics from `.test(...)` call "]},{"cell_type":"code","metadata":{"id":"5dIfb4iBxswP"},"source":["trainer.test(advanced_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YAVuxyQS9o0h"},"source":["### Custom metrics \n","\n","We can log metrics that we want to calculate after .fit ends.\n","For example let's calculate `accuracy_score` and use `.log_metric` method to log it to Neptune."]},{"cell_type":"code","metadata":{"id":"IjEhpzfAxq0Z"},"source":["advanced_model.freeze()\n","test_loader = DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor()), batch_size=256)\n","\n","y_true, y_pred = [],[]\n","for i, (x, y) in enumerate(test_loader):\n","    y_hat = advanced_model.forward(x).argmax(axis=1).cpu().detach().numpy()\n","    y = y.cpu().detach().numpy()\n","\n","    y_true.append(y)\n","    y_pred.append(y_hat)\n","\n","    if i == len(test_loader):\n","        break\n","y_true = np.hstack(y_true)\n","y_pred = np.hstack(y_pred)\n","\n","# Log additional metrics\n","from sklearn.metrics import accuracy_score\n","\n","accuracy = accuracy_score(y_true, y_pred)\n","neptune_logger.experiment.log_metric('test_accuracy', accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Lj6vJs19ymf"},"source":["### Performance charts\n","\n","You can log performance charts like ROC AUC or Confusion Matrix.\n","\n","Just use `.log_image` method on a matplotlib figure you want to log."]},{"cell_type":"code","metadata":{"id":"vBdh5uzcxnDg"},"source":["from scikitplot.metrics import plot_confusion_matrix\n","\n","fig, ax = plt.subplots(figsize=(16, 12))\n","plot_confusion_matrix(y_true, y_pred, ax=ax)\n","neptune_logger.experiment.log_image('confusion_matrix', fig)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WaLmZXGv-LpH"},"source":["# Log artifacts\n","\n","You can log any file to Neptune. just use the `.log_artifact` method.\n","\n","For example, we can log the entire 'CHECKPOINTS_DIR' directory."]},{"cell_type":"code","metadata":{"id":"bTrDV7nNxkuv"},"source":["neptune_logger.experiment.log_artifact(CHECKPOINTS_DIR)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VnD5OhCZ-cG_"},"source":["# Stop the logger\n","\n","After everything is done you need to stop the logger."]},{"cell_type":"code","metadata":{"id":"yGMl492CxfQC"},"source":["# You can stop the experiment\n","neptune_logger.experiment.stop()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ivaymA_e-ghn"},"source":["## Explore in Neptune\n","\n","Now you can explore everything you logged in Neptune.\n","\n","You can use your link or go check out [this experiment](https://ui.neptune.ai/o/shared/org/pytorch-lightning-integration/e/PYTOR-119/logs):\n","\n","![image](https://neptune.ai/wp-content/uploads/lightning_advanced.gif)\n","\n","# Fetch experiments after training\n","\n","Neptune lets you access everything you logged programatically.\n","\n","## Fetch experiment dashboard\n","\n","You can get the dashboard table into `pandas.DataFrame`"]},{"cell_type":"code","metadata":{"id":"x8xrAKV__EEn"},"source":["import neptune\n","\n","project = neptune.init(api_token=\"ANONYMOUS\",\n","                       project_qualified_name='shared/pytorch-lightning-integration')\n","project.get_leaderboard().head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ml44O_-L_IJg"},"source":["## Visualize experiments with Hiplot\n","\n","With [Neptune - HiPlot integration](https://docs.neptune.ai/integrations/hiplot.html) you can visualize all your experiment metrics and hyperparameters. "]},{"cell_type":"code","metadata":{"id":"JgSZecf5_joA"},"source":["from neptunecontrib.viz.parallel_coordinates_plot import make_parallel_coordinates_plot\n","\n","make_parallel_coordinates_plot(metrics= ['train_loss', 'val_loss', 'test_accuracy'],\n","                               params = ['max_epochs', 'batch_size', 'lr'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3uZ8Cz1__n5L"},"source":["## Update Experiment\n","\n","You can also fetch a single experiment and update it with some external metric calculated after training.\n"]},{"cell_type":"code","metadata":{"id":"bWVGxs-S_vAC"},"source":["exp = project.get_experiments(id='PYTOR-63')[0]\n","exp.log_metric('some_external_metric', 0.92)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RS6EVd2c_zYf"},"source":["## Create your free account\n","\n","The best part is, Neptune is completely free for individuals and research teams so you can go ahead and [create your free account](https://neptune.ai?utm_source=colab&utm_medium=notebook&utm_campaign=integration-pytorch-lightning) and check it out for yourself."]}]}